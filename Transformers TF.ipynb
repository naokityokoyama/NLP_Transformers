{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa44e445-c5db-45f6-ade9-b3088f504bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset squad_v1_pt (/home/studio-lab-user/.cache/huggingface/datasets/squad_v1_pt/default/1.1.0/65162e0fbe44f19a4d2ad9f5f507d2e965e74249fc3239dc78b4e3bd93bab7c4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dcc64b3b23429097e320d79a00c658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"squad_v1_pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58389bfa-a6c3-432a-b4ae-650e12eed081",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_datasets['train'].select(range(1000))\n",
    "validation = raw_datasets['validation'].select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "819a91ac-7620-4a95-b90b-253e78f964d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1beab8c761cb48578e63063331900fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eb6a2c0e9848859e1e1ff840e9bd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/918 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedc1119769f4c50a353304ce1563a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15504d6b005d44a3a27142e74cb9e6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"pierreguillou/bert-large-cased-squad-v1.1-portuguese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdbba0a5-6b1f-4afd-9298-435e2ef0a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb08e206-391a-467c-9490-500874cedf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9115b1f63cbd4dee8121decb9568be7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 1090)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train.map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "len(train), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea20e8f9-7b64-4ae8-b70a-2b9c7b154181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4218712b-c3cf-4eeb-a1ab-6c18c36511bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef5008df15d414fa1e82b58b24ad381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = validation.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "len(validation), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7beab068-f33d-47f0-8043-2ba6ec3a887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "from transformers import create_optimizer\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6ce5afb-95f3-4709-bddd-6586b2bf9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data collator\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6a74eaa-aa9b-4c84-a3b8-72cf42c5b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = train_dataset.to_tf_dataset(\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"start_positions\",\n",
    "        \"end_positions\",\n",
    "        \"attention_mask\",\n",
    "        \"token_type_ids\",\n",
    "    ],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17ebeeed-34ff-47b1-a1ae-d548d94328a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_eval_dataset = validation_dataset.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b2f6b23-0d0d-45dd-815c-ca40aeef80d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccec3024ce4f480899b440493fdb50f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at pierreguillou/bert-large-cased-squad-v1.1-portuguese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53a09b7d-4821-4834-bbe7-8e6938f31b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "num_train_epochs = 2\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1162286e-15ee-4ffa-a1a6-cc5cb88ba98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 20:30:05.856656: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 96.00MiB (rounded to 100663296)requested by op tf_bert_for_question_answering/bert/encoder/layer_._7/intermediate/Gelu/Erf\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-06-29 20:30:05.858086: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ****************************************************************************************************\n",
      "2022-06-29 20:30:05.858127: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'tf_bert_for_question_answering/bert/encoder/layer_._7/intermediate/Gelu/Erf' defined at (most recent call last):\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_883/4156300600.py\", line 1, in <module>\n      model.fit(tf_train_dataset,  epochs=num_train_epochs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1117, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1961, in run_call_with_unpacked_inputs\n      # pre-trained weights.\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1982, in call\n      outputs = self.bert(\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1961, in run_call_with_unpacked_inputs\n      # pre-trained weights.\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 869, in call\n      encoder_outputs = self.encoder(\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 554, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 560, in call\n      layer_outputs = layer_module(\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 516, in call\n      intermediate_output = self.intermediate(hidden_states=attention_output)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 420, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/activations.py\", line 351, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tf_bert_for_question_answering/bert/encoder/layer_._7/intermediate/Gelu/Erf'\nfailed to allocate memory\n\t [[{{node tf_bert_for_question_answering/bert/encoder/layer_._7/intermediate/Gelu/Erf}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_48495]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_883/4156300600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tf_bert_for_question_answering/bert/encoder/layer_._7/intermediate/Gelu/Erf' defined at (most recent call last):\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_883/4156300600.py\", line 1, in <module>\n      model.fit(tf_train_dataset,  epochs=num_train_epochs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1117, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1961, in run_call_with_unpacked_inputs\n      # pre-trained weights.\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1982, in call\n      outputs = self.bert(\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1961, in run_call_with_unpacked_inputs\n      # pre-trained weights.\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 869, in call\n      encoder_outputs = self.encoder(\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 554, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 560, in call\n      layer_outputs = layer_module(\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 516, in call\n      intermediate_output = self.intermediate(hidden_states=attention_output)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 420, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/activations.py\", line 351, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tf_bert_for_question_answering/bert/encoder/layer_._7/intermediate/Gelu/Erf'\nfailed to allocate memory\n\t [[{{node tf_bert_for_question_answering/bert/encoder/layer_._7/intermediate/Gelu/Erf}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_48495]"
     ]
    }
   ],
   "source": [
    "model.fit(tf_train_dataset,  epochs=num_train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431fba44-bbe6-44aa-9315-a503baa618d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss 3.1439 distilbert-base-uncased pt\n",
    "#loss 3.6569 distilbert-base-uncased en\n",
    "#loss 2.7413 bert-base-cased en  \n",
    "#loss 2.5509 bert-base-cased pt\n",
    "#loss 2.7358 neuralmind/bert-base-portuguese-cased pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
