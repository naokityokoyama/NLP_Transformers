{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f094c0-4d0c-4382-940a-5419cf152b2a",
   "metadata": {},
   "source": [
    "### load lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a8c349-ee83-488b-9b5f-c4775dd13056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator, DataCollatorWithPadding\n",
    "from transformers import create_optimizer\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "import numpy as np\n",
    "import collections\n",
    "from datasets import load_metric, load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526aa30-e9a6-4163-814c-1ae5379abc34",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa44e445-c5db-45f6-ade9-b3088f504bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset squad_v1_pt (/home/studio-lab-user/.cache/huggingface/datasets/squad_v1_pt/default/1.1.0/65162e0fbe44f19a4d2ad9f5f507d2e965e74249fc3239dc78b4e3bd93bab7c4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd11b656dd44315baddeeabf43fe867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad_v1_pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e8091-28ca-449d-be02-e4e5f7e9df5b",
   "metadata": {},
   "source": [
    "### sep train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58389bfa-a6c3-432a-b4ae-650e12eed081",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_datasets['train'].select(range(5000))\n",
    "validation = raw_datasets['validation'].select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa55b1-859a-48c2-b8d4-a5fdd479534b",
   "metadata": {},
   "source": [
    "### load tokenizer / Load model finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819a91ac-7620-4a95-b90b-253e78f964d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_checkpoint = 'distilbert-base-uncased'\n",
    "model_checkpoint = 'neuralmind/bert-base-portuguese-cased'\n",
    "\n",
    "#model_checkpoint = \"pierreguillou/bert-base-cased-squad-v1.1-portuguese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43382e6-b6a7-405f-b026-6299c6b6fb80",
   "metadata": {},
   "source": [
    "### prepare train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbba0a5-6b1f-4afd-9298-435e2ef0a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb08e206-391a-467c-9490-500874cedf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_training_examples at 0x7fd8ad7c7f70> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8403bdf211a44a76ab771129711cbc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 5252)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train.map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=train.column_names,\n",
    ")\n",
    "len(train), len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afece891-8c16-41d5-b6d6-405f2d731709",
   "metadata": {},
   "source": [
    "### prepare test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea20e8f9-7b64-4ae8-b70a-2b9c7b154181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4218712b-c3cf-4eeb-a1ab-6c18c36511bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe017e3fe5e4d9992f5c63c62a3668a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 1025)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = validation.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=validation.column_names,\n",
    ")\n",
    "len(validation), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8a577-7311-45c3-98f0-1a5759780774",
   "metadata": {},
   "source": [
    "### data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ce5afb-95f3-4709-bddd-6586b2bf9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data collator\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "#data_collator = DataCollatorWithPadding(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a3723-3e07-4c64-b552-5b40d8fdd71e",
   "metadata": {},
   "source": [
    "### transform train e test for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a74eaa-aa9b-4c84-a3b8-72cf42c5b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = train_dataset.to_tf_dataset(\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"start_positions\",\n",
    "        \"end_positions\",\n",
    "        \"attention_mask\",\n",
    "        \"token_type_ids\",\n",
    "    ],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ebeeed-34ff-47b1-a1ae-d548d94328a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_eval_dataset = validation_dataset.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9234158-987d-4ec2-bea0-ff13f6fbd7ef",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2f6b23-0d0d-45dd-815c-ca40aeef80d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some layers of TFBertForQuestionAnswering were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d0f6f-a83c-4f2d-bf90-6e4682cb68ab",
   "metadata": {},
   "source": [
    "### Login for save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293eca85-2ec1-4aec-8b99-183d06370391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e476bad83c244412b7deb5fa78de1de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9edbf-e109-47e6-9347-67d08cf0a7c4",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53a09b7d-4821-4834-bbe7-8e6938f31b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! Please ensure your labels are passed as keys in the input dict so that they are accessible to the model during the forward pass. To disable this behaviour, please pass a loss argument, or explicitly pass loss=None if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "num_train_epochs = 3\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "#callback = PushToHubCallback(output_dir=\"bert-squad\", tokenizer=tokenizer)\n",
    "model.compile(optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1162286e-15ee-4ffa-a1a6-cc5cb88ba98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "329/329 [==============================] - 485s 1s/step - loss: 2.7440 - val_loss: -4.8089\n",
      "Epoch 2/3\n",
      "329/329 [==============================] - 475s 1s/step - loss: 1.6194 - val_loss: -5.6097\n",
      "Epoch 3/3\n",
      "329/329 [==============================] - 477s 1s/step - loss: 1.2895 - val_loss: -5.8366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8ac055520>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_train_dataset, validation_data=tf_eval_dataset  , epochs=num_train_epochs)#, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "431fba44-bbe6-44aa-9315-a503baa618d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000 / 100\n",
    "#loss 2.7530 distilbert-base-uncased pt  \n",
    "#loss 2.2220 neuralmind/bert-base-portuguese-cased\n",
    "#loss 0.9221 pierreguillou/bert-base-cased-squad-v1.1-portuguese pt\n",
    "\n",
    "\n",
    "#5000 / 1000\n",
    "#loss 0.7623 pierreguillou/bert-base-cased-squad-v1.1-portuguese pt\n",
    "##loss 2.1048 distilbert-base-uncased pt\n",
    "#loss 1.2895 neuralmind/bert-base-portuguese-cased\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615afb1-efa6-4e63-b2bb-3b3fd6beb29c",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce71a07-05e5-410c-8e9a-276c254d078c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297bb9e600a14294ad51a79dc5b9879b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_eval_set = validation.select(range(100))\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "#trained_checkpoint = 'pierreguillou/bert-base-cased-squad-v1.1-portuguese'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "eval_set = small_eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=validation.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e2f3c4c-8719-426d-be3b-3a5fd41caba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-cased-distilled-squad were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased-distilled-squad and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"numpy\")\n",
    "\n",
    "batch = {k: eval_set_for_model[k] for k in eval_set_for_model.column_names}\n",
    "trained_model = TFAutoModelForQuestionAnswering.from_pretrained(trained_checkpoint)\n",
    "\n",
    "outputs = trained_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2b169e2-09dd-4864-a51f-30fd2b27a130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "metric = load_metric(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27e67044-1056-499e-bb17-bd3836aff4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd2bf74-ed57-4c35-bdbe-ccf6a546d688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 16s 203ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc9f85582a54051bef4430d25da5ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 1.542100283822138, 'f1': 2.2966459313435545}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(tf_eval_dataset)\n",
    "compute_metrics(\n",
    "    predictions[\"start_logits\"],\n",
    "    predictions[\"end_logits\"],\n",
    "    validation_dataset,\n",
    "    raw_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a6fb427-8ab7-40a9-a284-d29354bd19f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pierreguillou/bert-base-cased-squad-v1.1-portuguese'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1000/100\n",
    "#f1 0.1683 neuralmind/bert-base-portuguese-cased\n",
    "#f1 0.0856 distilbert-base-uncased\n",
    "#f1 0.5701 pierreguillou/bert-base-cased-squad-v1.1-portuguese\n",
    "\n",
    "#5000/1000\n",
    "#f1 5.6934 pierreguillou/bert-base-cased-squad-v1.1-portuguese\n",
    "#f1 2.2966 distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbeed6c-fb51-46e6-a3dc-a1ab3bc8d3b6",
   "metadata": {},
   "source": [
    "### Previsão / Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3750aa49-317b-47c4-bbb3-0c7c5a13b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at bert-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_save = 'bert-squad'\n",
    "question_answerer = pipeline(\"question-answering\", model=model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b882c64-6d7f-42fb-b531-cb25ab1b3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexto = context = r\"\"\"\n",
    "A pandemia de COVID-19, também conhecida como pandemia de coronavírus, é uma pandemia em curso de COVID-19, \n",
    "uma doença respiratória aguda causada pelo coronavírus da síndrome respiratória aguda grave 2 (SARS-CoV-2). \n",
    "A doença foi identificada pela primeira vez em Wuhan, na província de Hubei, República Popular da China, \n",
    "em 1 de dezembro de 2019, mas o primeiro caso foi reportado em 31 de dezembro do mesmo ano. \n",
    "Acredita-se que o vírus tenha uma origem zoonótica, porque os primeiros casos confirmados \n",
    "tinham principalmente ligações ao Mercado Atacadista de Frutos do Mar de Huanan, que também vendia animais vivos. \n",
    "Em 11 de março de 2020, a Organização Mundial da Saúde declarou o surto uma pandemia. Até 8 de fevereiro de 2021, \n",
    "pelo menos 105 743 102 casos da doença foram confirmados em pelo menos 191 países e territórios, \n",
    "com cerca de 2 308 943 mortes e 58 851 440 pessoas curadas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55993cb6-bfd2-45fa-b11f-7bcc1b81a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Quando começou a pandemia de Covid-19 no mundo?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f82816c4-2f34-4448-9252-002aef7ad1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'A pandemia', score: 0.031, start: 1, end: 11\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=question, context=contexto)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f0616-6455-43ad-8f74-223a0bdd1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'score': 0.0014 distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b837d8e1-abcd-4b6f-bd36-c360e35ebb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Qual é a data de início da pandemia Covid-19 em todo o mundo?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00d4b96a-8e44-451a-b4bf-86f0a3d09399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'coronavírus', score: 0.0254, start: 59, end: 70\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=question, context=contexto)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb3933a6-6d40-44fc-944f-5b9a99ff7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"O qué a pandemia de Covid-19?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c55c6e87-98db-4d18-b728-7d50b517d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'coronavírus', score: 0.0205, start: 59, end: 70\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=question, context=contexto)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65025314-9931-4f9e-8ccf-f19687ae5d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
